# 2-secured_and_monitored_web_infrastructure

## For every additional element, why you are adding it:
In this structure we've added three firewalls and an SSL certificate.
Firewalls enforce access control policies, allowing organizations to specify which traffic is allowed or denied based on source IP addresses, ports, protocols, or other criteria. so we've added a firewall in our load balancer in order to filter incoming traffic before it reaches the backend servers. This allows to enforce access control policies and block malicious traffic at the network perimeter, reducing the risk of attacks reaching the application layer, we've also added two other firewalls in our servers, this helps prevent unauthorized access to sensitive resources.
We also used an SSL certificate in order to establish secure encrypted connections between the client (such as a web browser) and the server (such as a web server) over the internet by using HTTPS protocol.

## What are firewalls for:
Firewalls are essential network security devices designed to monitor and control incoming and outgoing network traffic based on predetermined security rules. They act as a barrier between trusted internal networks (such as a company's internal network) and untrusted external networks (such as the internet), allowing organizations to enforce security policies, protect sensitive data, and mitigate various types of cyber threats.
## Why is the traffic served over HTTPS:
Because HTTPS is encrypted and secured using SSL/TLS (Secure Sockets Layer/Transport Layer Security) protocols, this means that even if somebody managed to break into the connection, they would not be able decrypt any of the data which passes between you and the website. Unlike HTTP which is not encrypted and can be read easily by any one.
 
## What monitoring is used for:
Monitoring tools track the performance metrics of various components in the IT infrastructure, such as servers, networks, databases, applications, and services. Performance monitoring helps identify bottlenecks, optimize resource utilization, and ensure that systems meet performance requirements and Service Level Agreements (SLAs).

## How the monitoring tool is collecting data:
Monitoring tools collect data from various sources within the IT infrastructure to provide insights into performance, availability, security, and other aspects of system operation. Here are some common methods used by monitoring tools to collect data:

1-Agent-Based Monitoring: Monitoring agents are lightweight software components installed on monitored devices (such as servers, workstations, network devices, and applications) to collect performance data locally. Agents gather information about CPU usage, memory utilization, disk I/O, network traffic, and other metrics and transmit it to a centralized monitoring server or platform for analysis and reporting.

2-Log File Monitoring: Monitoring tools analyze log files generated by servers, applications, operating systems, and network devices to extract valuable information about system events, errors, warnings, and performance indicators. Log file monitoring helps identify issues, track user activities, detect security incidents, and troubleshoot problems in the IT infrastructure.

## Explain what to do if you want to monitor your web server QPS:
To monitor the QPS of your web server, you can follow these steps:

1-Select a Monitoring Tool: Choose a monitoring tool or software solution that is capable of collecting and analyzing performance metrics, including QPS, from your web server. There are many monitoring tools available, both open-source and commercial, that can help you monitor various aspects of your server's performance.

2-Configure Monitoring Metrics: Configure the monitoring tool to collect and track relevant metrics, including QPS, from your web server. This may involve installing monitoring agents or agents on the server, configuring data collection settings, and defining the metrics you want to monitor.

3-Set Up Data Collection: Ensure that the monitoring tool is set up to collect data at regular intervals, such as every second or every few seconds, depending on your monitoring requirements and the level of granularity you need for analyzing server performance.

4-Analyze Monitoring Data: Monitor and analyze the data collected by the monitoring tool to track the QPS of your web server over time. Look for patterns, trends, and fluctuations in QPS that may indicate changes in server load, traffic patterns, or performance issues.

5-Set Thresholds and Alerts: Define thresholds for acceptable QPS levels based on your server's capacity and performance requirements. Configure the monitoring tool to trigger alerts or notifications when QPS exceeds or falls below these thresholds, indicating potential performance issues or anomalies that require attention.

## Some issues with this infrastructure:
### Why terminating SSL at the load balancer level is an issue:
Decrypting SSL traffic requires computational resources, including CPU and memory, on the load balancer. When SSL termination is performed at the load balancer level, it can significantly increase the processing load on the load balancer, especially in high-traffic environments. This increased load may impact the performance and scalability of the load balancer, potentially leading to bottlenecks and degraded performance.
When SSL termination occurs at the load balancer, decrypted traffic is transmitted in clear text between the load balancer and the backend servers. This introduces a potential security risk, as sensitive information, such as authentication credentials or personal data, may be exposed to unauthorized access or interception within the internal network. To mitigate this risk, additional security measures such as network segmentation, encryption, or access controls may be necessary to protect the integrity and confidentiality of data within the internal network.
### Why having only one MySQL server capable of accepting writes is an issue:
Relying on only one MySQL server to accept write operations can present several challenges and potential issues:
- Single Point of Failure (SPOF): If the MySQL server that accepts write operations fails or becomes unavailable, all write operations to the database will be disrupted. This creates a single point of failure in the system, leading to downtime, data loss, and potential service disruptions for applications and users relying on the database. 
- Scalability Limitations: A single MySQL server may not be able to handle the volume of write operations and traffic generated by applications with high throughput or large user bases. As the workload increases, the MySQL server may become overwhelmed, leading to performance degradation, latency issues, and bottlenecks.

### Why having servers with all the same components (database, web server and application server) might be a problem:
Having servers with identical components (such as database, web server, and application server) can present several potential issues and challenges:
- Resource Imbalance: Servers with identical components may not have the same resource requirements or workload characteristics. For example, the database server may require more CPU and memory resources to handle database queries and transactions efficiently, while the web server may prioritize network bandwidth and I/O throughput for serving web requests. By allocating identical resources to all servers, organizations risk under-provisioning or over-provisioning resources, leading to inefficient resource utilization, performance bottlenecks, and suboptimal application performance.
- Single Point of Failure: Servers with identical components may introduce a single point of failure in the system, where the failure of one server can impact the entire application or service. For example, if all database servers in a cluster have the same hardware configuration and software stack, a hardware failure or software bug affecting one server could potentially affect all servers in the cluster, leading to downtime or data loss.
- Lack of Flexibility and Adaptability: Servers with identical components may lack flexibility and adaptability to accommodate changing workload patterns, user demands, and application requirements. For example, if the application experiences sudden spikes in traffic or seasonal fluctuations in demand, servers with fixed configurations may struggle to scale up or down dynamically to meet changing performance and capacity requirements.
